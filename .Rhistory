train <- read.csv("train.csv", header = TRUE)
test <- read.csv("test.csv", header = TRUE)
train[]
train$question1
is.null(1)
any(is.null(train$question1))
any(is.null(train$question1[,]))
any(is.null(train$question1[]))
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE)
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE)
is.null(train$question1)
is.null(train$question1[,])
is.null(train$question1[])
train$question1
train$question1 == NULL
is.na(train$question1)
train <- train[!is.na(train$question1), ]
train <- train[!is.na(train$question2), ]
anyNA(train$question1)
anyNA(train$question2)
anyNA(test$question1)
anyNA(test$question2)
for(id in 1:nrow(train)){
if(is.null(train$question1[id])){
print(id)
}
#questionCorpus <- VCorpus(VectorSource(c(question1, question2)))
#questionCorpus <- transformCorpus(questionCorpus)
#dtm <- DocumentTermMatrix(questionCorpus)
#dtm2 <- weightTfIdf(dtm)
#test$distance[id] <- dist(dtm2)
}
for(id in 1:nrow(train)){
if(train$question1[id] == ""){
print(id)
}
#questionCorpus <- VCorpus(VectorSource(c(question1, question2)))
#questionCorpus <- transformCorpus(questionCorpus)
#dtm <- DocumentTermMatrix(questionCorpus)
#dtm2 <- weightTfIdf(dtm)
#test$distance[id] <- dist(dtm2)
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
anyNA(train)
anyNA(train$question1)
anyNA(train$question2)
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
library(tm)
library(stringr)
library(wordnet)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
train <- na.exclude(train)
is.na(train)
anyNa(train)
anyNA(train)
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
na.exclude(train)
na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
a
library(tm)
library(stringr)
library(wordnet)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
stopifnot(initDict())
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
reviews <- tm_map(reviews, f, "\\W|\\d|_", " ")
reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removeWords, stopwords("english"))
# reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
calculateDistance(trainSample)
calculateDistance(testSample)
warnings()
id = 1
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
X <- trainSample
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
dtm$nrow
library(tm)
library(stringr)
library(wordnet)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
stopifnot(initDict())
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
reviews <- tm_map(reviews, f, "\\W|\\d|_", " ")
reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removeWords, stopwords("english"))
# reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(dtm$ncol == 0){
print(X$question1)
print(X$question2)
}
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
calculateDistance(trainSample)
library(tm)
library(stringr)
library(wordnet)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
stopifnot(initDict())
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
reviews <- tm_map(reviews, f, "\\W|\\d|_", " ")
reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removeWords, stopwords("english"))
# reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(dtm$ncol == 0){
print(X$question1[id])
print(X$question2[id])
}
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
calculateDistance(trainSample)
warnings()
library(tm)
library(stringr)
library(wordnet)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
stopifnot(initDict())
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
#f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
#reviews <- tm_map(reviews, f, "\\W|\\d|_", " ")
#reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removePunctuation)
reviews <- tm_map(reviews, removeWords, stopwords("english"))
# reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(dtm$ncol == 0){
print(X$question1[id])
print(X$question2[id])
}
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
calculateDistance(trainSample)
calculateDistance(testSample)
warnings()
inspect(dtm)
length(dtm$i)
dtm$i
dtm$j
dtm$terms
length(dtm$dimnames$Docs)
length(dtm$dimnames$Terms)
dtm[1,]
dtm[1,]$ncol
dtm[1,]$nrow
dtm[1,]$i
dtm[1,]$j
dtm[2,]$i
sum(dtm[1,]$i)
sum(dtm[1,]$j)
sum(dtm[2,]$i)
library(tm)
library(stringr)
library(wordnet)
library(randomForest)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
stopifnot(initDict())
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
#f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
#reviews <- tm_map(reviews, f, "\\W|\\d|_", " ")
#reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removePunctuation)
reviews <- tm_map(reviews, removeWords, stopwords("english"))
# reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(sum(dtm[1,]$i) == 0){
print(X$question1[id])
}
if(sum(dtm[2,]$i) == 0){
print(X$question2[id])
}
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- test[sample(nrow(test), 100000),]
calculateDistance(trainSample)
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(sum(dtm[1,]$i) == 0){
print(X$question1[id])
print(dtm[1,])
}
if(sum(dtm[2,]$i) == 0){
print(X$question2[id])
print(dtm[2,])
}
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
}
calculateDistance(trainSample)
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
reviews <- tm_map(reviews, f, "'[]\\?!\"\'#$%&(){}+*/:;,._`|~\\[<=>@\\^-]'", " ")
reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removeWords, stopwords("english"))
##reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance(trainSample)
install.packages('randomForest')
library(randomForest)
m <- ramdomForest(is_duplicate ~ distance, trainSample)
m <- randomForest(is_duplicate ~ distance, trainSample)
trainSampleSimple <- trainSample[,c("distance", "is_duplicate")]
View(trainSample)
calculateDistance(trainSample)
View(trainSample)
trainSample$distance
trainSample$distance[1] <- 1
trainSample$distance
calculateDistance(trainSample)
View(trainSample)
trainSample <- calculateDistance(trainSample)
trainSample <- train[sample(nrow(train), 20000),]
for(id in 1:nrow(trainSample)){
questionCorpus <- VCorpus(VectorSource(c(trainSample$question1[id], trainSample$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(sum(dtm[1,]$i) == 0){
print(trainSample$question1[id])
print(dtm[1,])
}
if(sum(dtm[2,]$i) == 0){
print(trainSample$question2[id])
print(dtm[2,])
}
dtm2 <- weightTfIdf(dtm)
trainSample$distance[id] <- dist(dtm2)
}
View(trainSample)
trainSampleSimple <- trainSample[,c("distance", "is_duplicate")]
m <- randomForest(is_duplicate ~ ., trainSampleSimple)
trainSampleSimple$is_duplicate <- as.character(trainSampleSimple$is_duplicate)
m <- randomForest(is_duplicate ~ ., trainSampleSimple)
m <- randomForest(is_duplicate ~ ., data = trainSampleSimple)
trainSampleSimple$is_duplicate <- as.logical(trainSampleSimple$is_duplicate)
View(trainSampleSimple)
trainSampleSimple <- trainSample[,c("distance", "is_duplicate")]
trainSampleSimple$is_duplicate <- as.logical(trainSampleSimple$is_duplicate)
m <- randomForest(is_duplicate ~ ., data = trainSampleSimple)
m
typeof(trainSampleSimple$is_duplicate)
typeof(trainSampleSimple$distance)
predict(m, trainSampleSimple$distance[1])
predict(m, trainSampleSimple$distance)
View(trainSampleSimple)
trainSampleSimple$distance
predict(m, trainSampleSimple$distance)
predict(m, trainSampleSimple[,"distance"])
predict(m, trainSampleSimple)
predict(m, trainSampleSimple[1])
trainSampleSimple[1]
trainSampleSimple[1,]
predict(m, trainSampleSimple[1,])
predict(m, trainSampleSimple[2,])
data(Glass, package = 'mlbench')
install.packages('mlbench')
install.packages('mlbench')
data(Glass, package = 'mlbench')
typeof(Glass$Type)
trainSampleSimple <- trainSample[,c("distance", "is_duplicate")]
trainSampleSimple$is_duplicate <- as.factor(trainSampleSimple$is_duplicate)
m <- randomForest(is_duplicate ~ ., data = trainSampleSimple)
m
predict(m, trainSampleSimple)
res <- predict(m, trainSampleSimple)
table(res, trainSampleSimple$is_duplicate)
library(tm)
library(stringr)
library(wordnet)
library(randomForest)
setDict("/usr/share/wordnet/dict")
Sys.setenv(WNHOME = "/usr/share/wordnet")
stopifnot(initDict())
transformCorpus <- function(reviews){
reviews <- tm_map(reviews, stripWhitespace)
reviews <- tm_map(reviews, content_transformer(tolower))
f <- content_transformer(function(x, pattern, sub) gsub(pattern, sub, x))
reviews <- tm_map(reviews, f, "'[]\\?!\"\'#$%&(){}+*/:;,._`|~\\[<=>@\\^-]'", " ")
reviews <- tm_map(reviews, f, "  ", " ")
reviews <- tm_map(reviews, removeWords, stopwords("english"))
##reviews <- tm_map(reviews, stemDocument)
return(reviews)
}
calculateDistance <- function(X){
for(id in 1:nrow(X)){
questionCorpus <- VCorpus(VectorSource(c(X$question1[id], X$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(sum(dtm[1,]$i) == 0){
print(X$question1[id])
print(dtm[1,])
}
if(sum(dtm[2,]$i) == 0){
print(X$question2[id])
print(dtm[2,])
}
dtm2 <- weightTfIdf(dtm)
X$distance[id] <- dist(dtm2)
}
X
}
train <- read.csv("train.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
test <- read.csv("test.csv", header = TRUE, stringsAsFactors = FALSE, na.strings = "")
train <- na.exclude(train)
test <- na.exclude(test)
set.seed(2017)
trainSample <- train[sample(nrow(train), 20000),]
testSample <- train[sample(nrow(test), 100000),]
for(id in 1:nrow(trainSample)){
questionCorpus <- VCorpus(VectorSource(c(trainSample$question1[id], trainSample$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(sum(dtm[1,]$i) == 0){
print(trainSample$question1[id])
print(dtm[1,])
}
if(sum(dtm[2,]$i) == 0){
print(trainSample$question2[id])
print(dtm[2,])
}
dtm2 <- weightTfIdf(dtm)
trainSample$distance[id] <- dist(dtm2)
}
for(id in 1:nrow(testSample)){
questionCorpus <- VCorpus(VectorSource(c(testSample$question1[id], testSample$question2[id])))
questionCorpus <- transformCorpus(questionCorpus)
dtm <- DocumentTermMatrix(questionCorpus)
if(sum(dtm[1,]$i) == 0){
print(testSample$question1[id])
print(dtm[1,])
}
if(sum(dtm[2,]$i) == 0){
print(testSample$question2[id])
print(dtm[2,])
}
dtm2 <- weightTfIdf(dtm)
testSample$distance[id] <- dist(dtm2)
}
trainSampleSimple <- trainSample[,c("distance", "is_duplicate")]
trainSampleSimple$is_duplicate <- as.factor(trainSampleSimple$is_duplicate)
testSampleSimple <- testSample[,c("distance", "is_duplicate")]
testSampleSimple$is_duplicate <- as.factor(testSampleSimple$is_duplicate)
m <- randomForest(is_duplicate ~ ., trainSampleSimple)
res <- predict(m, testSampleSimple)
table(res, testSampleSimple$is_duplicate)
save(trainSampleSimple, file="trainSampleSimple.rdata")
save(testSampleSimple, file="testSampleSimple.rdata")
save(testSample, file="testSample.rdata")
save(trainSample, file="trainSample.rdata")
tables <- table(res, testSampleSimple$is_duplicate)
error <- 1-(sum(diag(tables)))/sum(tables)
error
